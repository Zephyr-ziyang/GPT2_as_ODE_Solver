{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from random import randint\n",
    "import uuid\n",
    "\n",
    "from quinine import QuinineArgumentParser\n",
    "from tqdm import tqdm\n",
    "import torch\n",
    "import yaml\n",
    "import numpy as np\n",
    "from eval import get_run_metrics\n",
    "from tasks import get_task_sampler\n",
    "from samplers import get_data_sampler,rand_select_sampler\n",
    "from curriculum import Curriculum\n",
    "from schema import schema\n",
    "from models import noconf_build_model\n",
    "import random\n",
    "import wandb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "modelfamily = \"raw\"\n",
    "model_n_dims = 50\n",
    "n_positions = 101\n",
    "n_embd = 256\n",
    "n_layer = 12\n",
    "n_head = 8\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'rawTransformerModel' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[3], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m model \u001b[38;5;241m=\u001b[39m \u001b[43mnoconf_build_model\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodelfamily\u001b[49m\u001b[43m,\u001b[49m\u001b[43mn_dims\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmodel_n_dims\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mn_positions\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mn_positions\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mn_embd\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mn_embd\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mn_layer\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mn_layer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mn_head\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mn_head\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      2\u001b[0m optimizer \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39moptim\u001b[38;5;241m.\u001b[39mAdam(model\u001b[38;5;241m.\u001b[39mparameters(), lr\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0.001\u001b[39m,weight_decay\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m)  \u001b[38;5;66;03m# add weight decay\u001b[39;00m\n\u001b[1;32m      5\u001b[0m model\u001b[38;5;241m.\u001b[39mcuda()\n",
      "File \u001b[0;32m~/project/src/models.py:56\u001b[0m, in \u001b[0;36mnoconf_build_model\u001b[0;34m(modelfamily, n_dims, n_positions, n_embd, n_layer, n_head)\u001b[0m\n\u001b[1;32m     48\u001b[0m     model \u001b[38;5;241m=\u001b[39m difTransformerModel(\n\u001b[1;32m     49\u001b[0m         n_dims\u001b[38;5;241m=\u001b[39mn_dims,\n\u001b[1;32m     50\u001b[0m         n_positions\u001b[38;5;241m=\u001b[39mn_positions, \u001b[38;5;66;03m# prompt xs length\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     53\u001b[0m         n_head\u001b[38;5;241m=\u001b[39mn_head,\n\u001b[1;32m     54\u001b[0m     )\n\u001b[1;32m     55\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m modelfamily \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mraw\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[0;32m---> 56\u001b[0m     model \u001b[38;5;241m=\u001b[39m \u001b[43mrawTransformerModel\u001b[49m(\n\u001b[1;32m     57\u001b[0m         n_dims\u001b[38;5;241m=\u001b[39mn_dims,\n\u001b[1;32m     58\u001b[0m         n_positions\u001b[38;5;241m=\u001b[39mn_positions, \u001b[38;5;66;03m# prompt xs length\u001b[39;00m\n\u001b[1;32m     59\u001b[0m         n_embd\u001b[38;5;241m=\u001b[39mn_embd,\n\u001b[1;32m     60\u001b[0m         n_layer\u001b[38;5;241m=\u001b[39mn_layer,\n\u001b[1;32m     61\u001b[0m         n_head\u001b[38;5;241m=\u001b[39mn_head,\n\u001b[1;32m     62\u001b[0m     )\n\u001b[1;32m     63\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m modelfamily \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mgptJ\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[1;32m     64\u001b[0m     model \u001b[38;5;241m=\u001b[39m TransformerModel(\n\u001b[1;32m     65\u001b[0m         n_dims\u001b[38;5;241m=\u001b[39mn_dims, \n\u001b[1;32m     66\u001b[0m         n_positions\u001b[38;5;241m=\u001b[39mn_positions, \u001b[38;5;66;03m# prompt xs length\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     69\u001b[0m         n_head\u001b[38;5;241m=\u001b[39mn_head,\n\u001b[1;32m     70\u001b[0m     )\n",
      "\u001b[0;31mNameError\u001b[0m: name 'rawTransformerModel' is not defined"
     ]
    }
   ],
   "source": [
    "model = noconf_build_model(modelfamily,n_dims=model_n_dims, n_positions=n_positions, n_embd=n_embd, n_layer=n_layer, n_head=n_head)\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.001,weight_decay=0)  # add weight decay\n",
    "\n",
    "\n",
    "model.cuda()\n",
    "model.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "taskname = 'ode_ivp_case2vec'\n",
    "dataname= 'ode_ivp_case2'\n",
    "If_enhanced_loss = False\n",
    "n_dims = 50\n",
    "n_points = 41\n",
    "bsize = 64"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_sampler = get_data_sampler(dataname,n_dims=n_dims)\n",
    "xs = data_sampler.sample_xs(\n",
    "    n_points,\n",
    "    bsize,\n",
    ")\n",
    "torch.save(xs, f'test_{dataname}_xs.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# xs = torch.load(f'test_{dataname}_xs.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_step(model, xs, ys, optimizer, loss_func): # 单个批次（batch）的前向传播、损失计算、反向传播和优化器更新\n",
    "    optimizer.zero_grad()\n",
    "    output = model(xs, ys)\n",
    "    loss = 2\n",
    "    # loss = loss_func(output, ys)\n",
    "    # loss.backward()\n",
    "    # optimizer.step()\n",
    "    # return loss.detach().item(), output.detach()\n",
    "    return loss, output.detach()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 检查checkpoints pt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ode_ivp_case2vec\n"
     ]
    }
   ],
   "source": [
    "print(taskname)\n",
    "y_task = get_task_sampler(taskname,n_dims=n_dims,batch_size=bsize)\n",
    "task_sampler = y_task()\n",
    "ys = task_sampler.evaluate(xs)  # 获取模型预测结果"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if If_enhanced_loss:\n",
    "            # 获取steptable\n",
    "            steptable = task_sampler.get_training_steptable(xs,use_h = False).cuda()\n",
    "            # 增强损失 每个数据点计算前几个的损失\n",
    "            loss_func = task_sampler.get_enhanced_training_metric(steptable)  # 损失metric\n",
    "            point_wise_loss_func = task_sampler.get_enhanced_metric(steptable)  # loss_func\n",
    "else:\n",
    "    loss_func = task_sampler.get_training_metric()  # 损失metric\n",
    "    point_wise_loss_func = task_sampler.get_metric()  # loss_func\n",
    "def mean_squared_error(ys_pred, ys):\n",
    "    return (ys).square().mean()\n",
    "loss_func = mean_squared_error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "shape '[64, 41, 1]' is invalid for input of size 131200",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[11], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m loss, output \u001b[38;5;241m=\u001b[39m \u001b[43mtrain_step\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mxs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mys\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moptimizer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mloss_func\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[7], line 3\u001b[0m, in \u001b[0;36mtrain_step\u001b[0;34m(model, xs, ys, optimizer, loss_func)\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mtrain_step\u001b[39m(model, xs, ys, optimizer, loss_func): \u001b[38;5;66;03m# 单个批次（batch）的前向传播、损失计算、反向传播和优化器更新\u001b[39;00m\n\u001b[1;32m      2\u001b[0m     optimizer\u001b[38;5;241m.\u001b[39mzero_grad()\n\u001b[0;32m----> 3\u001b[0m     output \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[43m(\u001b[49m\u001b[43mxs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mys\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      4\u001b[0m     loss \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m2\u001b[39m\n\u001b[1;32m      5\u001b[0m     \u001b[38;5;66;03m# loss = loss_func(output, ys)\u001b[39;00m\n\u001b[1;32m      6\u001b[0m     \u001b[38;5;66;03m# loss.backward()\u001b[39;00m\n\u001b[1;32m      7\u001b[0m     \u001b[38;5;66;03m# optimizer.step()\u001b[39;00m\n\u001b[1;32m      8\u001b[0m     \u001b[38;5;66;03m# return loss.detach().item(), output.detach()\u001b[39;00m\n",
      "File \u001b[0;32m~/anaconda3/envs/in-context-learning/lib/python3.8/site-packages/torch/nn/modules/module.py:1110\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1106\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1107\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1108\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1109\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1110\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1111\u001b[0m \u001b[38;5;66;03m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1112\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[38;5;241m=\u001b[39m [], []\n",
      "File \u001b[0;32m~/project/src/models.py:322\u001b[0m, in \u001b[0;36mrawTransformerModel.forward\u001b[0;34m(self, xs, ys, inds)\u001b[0m\n\u001b[1;32m    320\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mmax\u001b[39m(inds) \u001b[38;5;241m>\u001b[39m\u001b[38;5;241m=\u001b[39m ys\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m1\u001b[39m] \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mmin\u001b[39m(inds) \u001b[38;5;241m<\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[1;32m    321\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124minds contain indices where xs and ys are not defined\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m--> 322\u001b[0m zs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_combine\u001b[49m\u001b[43m(\u001b[49m\u001b[43mxs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mys\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    323\u001b[0m embeds \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_read_in(zs)\n\u001b[1;32m    324\u001b[0m output \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backbone(inputs_embeds\u001b[38;5;241m=\u001b[39membeds)\u001b[38;5;241m.\u001b[39mlast_hidden_state\n",
      "File \u001b[0;32m~/project/src/models.py:306\u001b[0m, in \u001b[0;36mrawTransformerModel._combine\u001b[0;34m(xs_b, ys_b)\u001b[0m\n\u001b[1;32m    302\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Interleaves the x's and the y's into a single sequence.\"\"\"\u001b[39;00m\n\u001b[1;32m    303\u001b[0m bsize, points, dim \u001b[38;5;241m=\u001b[39m xs_b\u001b[38;5;241m.\u001b[39mshape\n\u001b[1;32m    304\u001b[0m ys_b_wide \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mcat(\n\u001b[1;32m    305\u001b[0m     (\n\u001b[0;32m--> 306\u001b[0m         \u001b[43mys_b\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mview\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbsize\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpoints\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m)\u001b[49m,\n\u001b[1;32m    307\u001b[0m         torch\u001b[38;5;241m.\u001b[39mzeros(bsize, points, dim \u001b[38;5;241m-\u001b[39m \u001b[38;5;241m1\u001b[39m, device\u001b[38;5;241m=\u001b[39mys_b\u001b[38;5;241m.\u001b[39mdevice),\n\u001b[1;32m    308\u001b[0m     ),\n\u001b[1;32m    309\u001b[0m     axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m2\u001b[39m,\n\u001b[1;32m    310\u001b[0m )\n\u001b[1;32m    311\u001b[0m zs \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mstack((xs_b, ys_b_wide), dim\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m2\u001b[39m)\n\u001b[1;32m    312\u001b[0m zs \u001b[38;5;241m=\u001b[39m zs\u001b[38;5;241m.\u001b[39mview(bsize, \u001b[38;5;241m2\u001b[39m \u001b[38;5;241m*\u001b[39m points, dim)\n",
      "\u001b[0;31mRuntimeError\u001b[0m: shape '[64, 41, 1]' is invalid for input of size 131200"
     ]
    }
   ],
   "source": [
    "loss, output = train_step(model, xs, ys, optimizer, loss_func)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2\n",
      "torch.Size([64, 50])\n"
     ]
    }
   ],
   "source": [
    "print(loss)\n",
    "print(output.size())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "in-context-learning",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
